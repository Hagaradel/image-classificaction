{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7198317,"sourceType":"datasetVersion","datasetId":4163262},{"sourceId":7199385,"sourceType":"datasetVersion","datasetId":4164061},{"sourceId":7218134,"sourceType":"datasetVersion","datasetId":4177549},{"sourceId":7225702,"sourceType":"datasetVersion","datasetId":4182917},{"sourceId":7230018,"sourceType":"datasetVersion","datasetId":4186038},{"sourceId":7232993,"sourceType":"datasetVersion","datasetId":4188268},{"sourceId":7233358,"sourceType":"datasetVersion","datasetId":4188522}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D ,MaxPool2D, Dense, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.optimizers import SGD,Adam\nfrom tensorflow.keras import regularizers\nimport cv2\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import BaggingClassifier\n# from keras.wrappers.scikit_learn import KerasClassifier","metadata":{"_uuid":"a707c7f2-136d-413e-9bd3-21a49901bd8b","_cell_guid":"b9a6ad2f-e64b-480d-91aa-b5837f814a41","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.127711Z","iopub.execute_input":"2023-12-27T20:51:50.128170Z","iopub.status.idle":"2023-12-27T20:51:50.135191Z","shell.execute_reply.started":"2023-12-27T20:51:50.128131Z","shell.execute_reply":"2023-12-27T20:51:50.134258Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"label = {\n    0: 'apple',\n    1: 'banana',\n    2: 'grape',\n    3: 'mango',\n    4: 'strawberry',\n}\n\ntrain_dir = '/kaggle/input/dataset11/dataset/dataset/train'\ntest_dir = '/kaggle/input/dataset11/dataset/dataset/test'\n\n\ntraining_data = []","metadata":{"_uuid":"5bb2272f-29e5-48db-8a6f-5d670910d915","_cell_guid":"b79ab7e6-1acc-4fb9-bcad-6e7eb5b90208","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.136791Z","iopub.execute_input":"2023-12-27T20:51:50.137088Z","iopub.status.idle":"2023-12-27T20:51:50.151415Z","shell.execute_reply.started":"2023-12-27T20:51:50.137063Z","shell.execute_reply":"2023-12-27T20:51:50.150603Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\n\n# # Preprocessing step\n\n#data augmentation \ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n) # pass your custom function here\n\ntest_datagen = ImageDataGenerator(rescale=1./255) # pass your custom function here","metadata":{"_uuid":"931f6ac2-a21b-493e-9c18-750c906c3bf6","_cell_guid":"b24deb04-b2a7-4f7a-adbf-a88acfbf4a8a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.152602Z","iopub.execute_input":"2023-12-27T20:51:50.152919Z","iopub.status.idle":"2023-12-27T20:51:50.161934Z","shell.execute_reply.started":"2023-12-27T20:51:50.152897Z","shell.execute_reply":"2023-12-27T20:51:50.161142Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\ndef is_image_file(file):\n    return file.lower().endswith(('.png', '.jpg', '.jpeg'))","metadata":{"_uuid":"d214fbc7-0c25-4ee0-9b35-c10145edc5b6","_cell_guid":"1bbbcbde-276d-44cb-8416-f1c2c9177f65","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.163648Z","iopub.execute_input":"2023-12-27T20:51:50.163923Z","iopub.status.idle":"2023-12-27T20:51:50.169924Z","shell.execute_reply.started":"2023-12-27T20:51:50.163896Z","shell.execute_reply":"2023-12-27T20:51:50.169051Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def create():\n    total = 9900\n    training_data = []\n\n    for i in range(1, 6):\n        pa = os.path.join(train_dir, str(i))\n        files = [file for file in os.listdir(pa) if is_image_file(file)]\n\n        for file in files:\n            total -= 1\n            path = os.path.join(pa, file)\n            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n            img_data = cv2.resize(img_data, (224, 224))\n            img_data = img_data.reshape(-1, 224, 224, 1)\n            img_data = img_data / 255.0\n\n            if total % 2 == 0:\n                img_ar = next(train_datagen.flow(img_data, batch_size=1))\n                training_data.append([np.array(img_ar), label[i - 1]])\n\n            training_data.append([np.array(img_data), label[i - 1]])\n\n    shuffle(training_data)\n    return training_data","metadata":{"_uuid":"cfd6f98c-1317-4489-9e36-090f75aed82e","_cell_guid":"61f42323-f6fb-4fbd-90ec-2ccee9332a4a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.171081Z","iopub.execute_input":"2023-12-27T20:51:50.171423Z","iopub.status.idle":"2023-12-27T20:51:50.179898Z","shell.execute_reply.started":"2023-12-27T20:51:50.171399Z","shell.execute_reply":"2023-12-27T20:51:50.178998Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def create_test_predict():\n    total = 100\n    test_data = []\n\n    files = [file for file in os.listdir(test_dir) if is_image_file(file)]\n\n    for file in files:\n        total -= 1\n        path = os.path.join(test_dir, file)\n        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img_data = cv2.resize(img_data, (224, 224))\n        img_data = img_data.reshape(-1, 224, 224, 1)\n\n        if total % 2 == 0:\n            img_ar = next(test_datagen.flow(img_data, batch_size=1))\n            test_data.append([np.array(img_ar)])\n\n        test_data.append([np.array(img_data)])\n\n    shuffle(test_data)\n    return test_data","metadata":{"_uuid":"6ea54aa0-0682-4e35-8b34-8974d5d60638","_cell_guid":"7e2a2165-e493-4608-930c-c129bef3f166","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.181125Z","iopub.execute_input":"2023-12-27T20:51:50.181658Z","iopub.status.idle":"2023-12-27T20:51:50.192203Z","shell.execute_reply.started":"2023-12-27T20:51:50.181625Z","shell.execute_reply":"2023-12-27T20:51:50.191264Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def create_test_predict(test_dir):\n    test_data = []\n\n    files = [file for file in os.listdir(test_dir) if is_image_file(file)]\n\n    for file in files:\n        path = os.path.join(test_dir, file)\n        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img_data = cv2.resize(img_data, (224, 224))\n        img_data = img_data.reshape(-1, 224, 224, 1)\n\n        test_data.append([np.array(img_data)])\n\n    shuffle(test_data)\n    return test_data\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T20:51:50.224497Z","iopub.execute_input":"2023-12-27T20:51:50.224753Z","iopub.status.idle":"2023-12-27T20:51:50.230547Z","shell.execute_reply.started":"2023-12-27T20:51:50.224730Z","shell.execute_reply":"2023-12-27T20:51:50.229659Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Assuming 'test_directory' is the path to your test image directory or test file\ntest_directory = '/kaggle/input/dataset11/dataset/dataset/test'  # Replace with the path to your actual test directory or file\n\nprediction_test = create_test_predict(test_directory)\n\nX_test = np.array([i[0] for i in prediction_test]).reshape(-1, 224, 224, 1)\nprint(len(X_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T20:51:50.232132Z","iopub.execute_input":"2023-12-27T20:51:50.232405Z","iopub.status.idle":"2023-12-27T20:51:50.297762Z","shell.execute_reply.started":"2023-12-27T20:51:50.232381Z","shell.execute_reply":"2023-12-27T20:51:50.295762Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'test_directory' is the path to your test image directory or test file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m test_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/dataset11/dataset/dataset/test\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your actual test directory or file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m prediction_test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_test_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m prediction_test])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test))\n","Cell \u001b[0;32mIn[32], line 4\u001b[0m, in \u001b[0;36mcreate_test_predict\u001b[0;34m(test_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_test_predict\u001b[39m(test_dir):\n\u001b[1;32m      2\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     files \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m is_image_file(file)]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m      7\u001b[0m         path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_dir, file)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/dataset11/dataset/dataset/test'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/dataset11/dataset/dataset/test'","output_type":"error"}]},{"cell_type":"code","source":"# ===========================================================================================================\ntrain_data= create()\n\nX_train = np.array([i[0] for i in train_data]).reshape(-1, 224, 224,1)\ny_train = np.array([i[1] for i in train_data])\n\n\nprint(y_train.shape)\nx_train, x_test, y_train, y_test = train_test_split(X_train, y_train, random_state=10, test_size=0.25,shuffle=True)\n#================================================================================================================================================","metadata":{"_uuid":"9c851d4f-8820-44bd-9c24-bce09ca8096f","_cell_guid":"f5d124ee-e8e7-4b80-833a-d3983f547716","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.298348Z","iopub.status.idle":"2023-12-27T20:51:50.298676Z","shell.execute_reply.started":"2023-12-27T20:51:50.298514Z","shell.execute_reply":"2023-12-27T20:51:50.298530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\n\ninteger_encoded = label_encoder.fit_transform(y_train)\ninteger_encoded_test=label_encoder.fit_transform(y_test)","metadata":{"_uuid":"f62f394a-278c-43b5-b985-7cb927d1e879","_cell_guid":"d0f6b348-6358-4878-bba7-21cd906ecb96","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.300085Z","iopub.status.idle":"2023-12-27T20:51:50.300410Z","shell.execute_reply.started":"2023-12-27T20:51:50.300257Z","shell.execute_reply":"2023-12-27T20:51:50.300271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def alex_net():\n    model = Sequential()\n\n    model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding='valid', input_shape=(224, 224, 1), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(3, 3), strides=2))\n\n    model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(3, 3), strides=2))\n\n    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(3, 3), strides=2))\n\n    model.add(Flatten())\n    model.add(Dense(units=4096, activation='relu',kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.010)))\n    model.add(Dropout(rate=0.5))\n\n    model.add(Dense(units=4096, activation='relu',kernel_regularizer=regularizers.l2(0.010), bias_regularizer=regularizers.l2(0.010)))\n    model.add(Dropout(rate=0.5))\n\n    model.add(Dense(units=5, activation='softmax'))\n    zf=zfnet()\n    model.add(zf)\n\n    return model","metadata":{"_uuid":"eea3ccbd-1255-4bea-ac8c-b0c759030b5b","_cell_guid":"e3c02c80-c7e8-43b9-aff2-20f7c62ac38f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.301553Z","iopub.status.idle":"2023-12-27T20:51:50.301904Z","shell.execute_reply.started":"2023-12-27T20:51:50.301716Z","shell.execute_reply":"2023-12-27T20:51:50.301732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef zfnet():\n    model = Sequential()\n\n    # Convolutional layers\n    model.add(Conv2D(96, (7, 7), strides=(2, 2), activation='relu', input_shape=(224,224,1)))\n    model.add(MaxPool2D((3, 3), strides=(2, 2)))\n\n    model.add(Conv2D(256, (5, 5), activation='relu'))\n    model.add(MaxPool2D((3, 3), strides=(2, 2)))\n\n    model.add(Conv2D(384, (3, 3), activation='relu'))\n    model.add(Conv2D(384, (3, 3), activation='relu'))\n    model.add(Conv2D(256, (3, 3), activation='relu'))\n    model.add(MaxPool2D((3, 3), strides=(2, 2)))\n\n    # Flatten layer\n    model.add(Flatten())\n\n    # Fully connected layers\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.3))\n\n    model.add(Dense(4096, activation='relu',kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n    model.add(Dropout(0.3))\n\n    model.add(Dense(units=5, activation='softmax'))\n\n    return model","metadata":{"_uuid":"1669240a-ad51-402f-8890-a0d1f751bdb5","_cell_guid":"b8d81ac3-da18-486c-aec0-1e431ea793f4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.303043Z","iopub.status.idle":"2023-12-27T20:51:50.303350Z","shell.execute_reply.started":"2023-12-27T20:51:50.303197Z","shell.execute_reply":"2023-12-27T20:51:50.303211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def LeNet5():\n    \n    model = Sequential()\n    \n    model.add(Conv2D(filters=6 , kernel_size=(5,5) , strides=(1,1) , activation=\"tanh\" , input_shape=(32 , 32,1 )))\n              \n    model.add(MaxPool2D((2,2)))\n    \n    model.add(Conv2D(filters=16 , kernel_size=(5,5) , strides=(1,1) , activation=\"tanh\" ))   \n                  \n    model.add(MaxPool2D((2,2)))\n              \n    model.add(Flatten())\n    \n    model.add(Dense(units=120 , activation=\"tanh\"))\n    \n    model.add(Dropout(0.2))\n    \n    model.add(Dense(units=84 , activation=\"tanh\"))\n    \n    model.add(Dropout(0.2))\n    \n    model.add(Dense(units=10 , activation=\"softmax\"))\n    \n    adam = Adam(learning_rate=0.01)\n    \n    model.compile(optimizer=adam , loss='sparse_categorical_crossentropy'  , metrics=['accuracy'])\n    \n    return model","metadata":{"_uuid":"2c05bdcd-e337-4d8b-89f2-353d5cc18fd1","_cell_guid":"4e3a5fa3-5f64-4a20-8fdb-4182d9b1a8e1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.304876Z","iopub.status.idle":"2023-12-27T20:51:50.305185Z","shell.execute_reply.started":"2023-12-27T20:51:50.305031Z","shell.execute_reply":"2023-12-27T20:51:50.305045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vgg16\ndef vgg_net():\n    model = Sequential()\n    model.add(Conv2D(filters=32, kernel_size=(7, 7), strides=1, padding='valid', input_shape=(224, 224,1),\n                     activation='relu'))\n    model.add(Conv2D(filters=32, kernel_size=(5, 5), strides=1, activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n   \n    \n    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n   \n\n    model.add(Conv2D(filters=96, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(Conv2D(filters=96, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(Conv2D(filters=96, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n#     model.add(Dropout(0.5))\n    \n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n#     model.add(Dropout(0.5))\n    \n    model.add(Dense(units=4096, activation='relu',kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.0001)))\n    model.add(Dropout(0.3))\n    model.add(Dense(units=4096, activation='relu',kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n    model.add(Dropout(0.3))\n    model.add(Dense(units=1000, activation='softmax'))\n\n    return model","metadata":{"_uuid":"83f2b3c5-3d86-4e7d-9508-a5fbf820ee86","_cell_guid":"756bd871-94d0-49e6-9f1e-8045b36a231e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.306076Z","iopub.status.idle":"2023-12-27T20:51:50.306378Z","shell.execute_reply.started":"2023-12-27T20:51:50.306226Z","shell.execute_reply":"2023-12-27T20:51:50.306240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nclass MultiHeadAttention(layers.Layer):\n    def __init__(self, d_model, n_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.n_heads = n_heads\n        self.d_model = d_model\n\n        self.query_dense = layers.Dense(d_model)\n        self.key_dense = layers.Dense(d_model)\n        self.value_dense = layers.Dense(d_model)\n        self.final_dense = layers.Dense(d_model)\n\n    def split_heads(self, x, batch_size):\n        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.d_model // self.n_heads))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n\n    def call(self, inputs):\n        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n        batch_size = tf.shape(query)[0]\n\n        # Linear layers\n        query = self.query_dense(query)\n        key = self.key_dense(key)\n        value = self.value_dense(value)\n\n        # Split heads\n        query = self.split_heads(query, batch_size)\n        key = self.split_heads(key, batch_size)\n        value = self.split_heads(value, batch_size)\n\n        # Scaled dot-product attention\n        scaled_attention, attention_weights = self.scaled_dot_product_attention(query, key, value, mask)\n\n        # Concatenate heads and apply final linear layer\n        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n        output = self.final_dense(concat_attention)\n\n        return output, attention_weights\n\n    def scaled_dot_product_attention(self, query, key, value, mask):\n        matmul_qk = tf.matmul(query, key, transpose_b=True)\n\n        # Scale matmul_qk\n        dk = tf.cast(tf.shape(key)[-1], tf.float32)\n        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n        # Add mask to the scaled tensor\n        if mask is not None:\n            scaled_attention_logits += (mask * -1e9)\n\n        # Softmax is normalized on the last axis (seq_len_k) so that the scores\n        # add up to 1.\n        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n\n        output = tf.matmul(attention_weights, value)\n\n        return output, attention_weights\n\nclass PositionalEncoding(layers.Layer):\n    def __init__(self, max_len, d_model):\n        super(PositionalEncoding, self).__init__()\n        self.encoding = self.positional_encoding(max_len, d_model)\n\n    def get_angles(self, pos, i, d_model):\n        angle_rates = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n        return pos * angle_rates\n\n    def positional_encoding(self, position, d_model):\n        angle_rads = self.get_angles(\n            pos=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n            d_model=d_model)\n        # apply sin to even indices in the array; 2i\n        sines = tf.math.sin(angle_rads[:, 0::2])\n        # apply cos to odd indices in the array; 2i+1\n        cosines = tf.math.cos(angle_rads[:, 1::2])\n\n        pos_encoding = tf.concat([sines, cosines], axis=-1)\n        pos_encoding = pos_encoding[tf.newaxis, ...]\n        return tf.cast(pos_encoding, tf.float32)\n\n    def call(self, inputs):\n        return inputs + self.encoding[:, :tf.shape(inputs)[1], :]\n\nclass VisionTransformerBlock(layers.Layer):\n    def __init__(self, d_model, n_heads, dff, dropout_rate=0.1):\n        super(VisionTransformerBlock, self).__init__()\n        self.attention = MultiHeadAttention(d_model, n_heads)\n        self.ffn = keras.Sequential([\n            layers.Dense(dff, activation='relu'),\n            layers.Dense(d_model)\n        ])\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(dropout_rate)\n        self.dropout2 = layers.Dropout(dropout_rate)\n\n    def call(self, inputs, training, mask):\n        attention_output, _ = self.attention({\n            'query': inputs,\n            'key': inputs,\n            'value': inputs,\n            'mask': mask\n        })\n        attention_output = self.dropout1(attention_output, training=training)\n        out1 = self.layernorm1(inputs + attention_output)\n\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)\n\nclass VisionTransformer(keras.Model):\n    def __init__(self, image_size, patch_size, num_layers, d_model, num_heads, dff, num_classes, rate=0.1):\n        super(VisionTransformer, self).__init__()\n\n        self.patch_size = patch_size\n        self.num_patches = (image_size // patch_size) ** 2\n        self.embedding_dim = d_model\n\n        self.flatten = layers.Flatten()\n        self.patch_embedding = layers.Conv2D(d_model, (patch_size, patch_size), strides=(patch_size, patch_size), activation='relu')\n        self.positional_encoding = PositionalEncoding(self.num_patches, d_model)\n\n        self.transformer_blocks = [VisionTransformerBlock(d_model, num_heads, dff) for _ in range(num_layers)]\n        self.dropout = layers.Dropout(rate)\n\n        self.classifier = layers.Dense(num_classes)\n\n    def call(self, inputs, training):\n        x = self.patch_embedding(inputs)\n        x = self.flatten(x)\n        x += self.positional_encoding(x)\n\n        mask = tf.linalg.band_part(tf.ones((self.num_patches, self.num_patches)), -1, 0)\n        mask = 1 - mask  # Lower triangular part of the matrix\n\n        for transformer_block in self.transformer_blocks:\n            x = transformer_block(x, training, mask)\n\n        x = self.dropout(x, training=training)\n        output = self.classifier(x)\n\n        return output\n\n# Example usage:\nimage_size = 224\npatch_size = 16\nnum_layers = 6\nd_model = 256\nnum_heads = 8\ndff = 512\nnum_classes = 5\ndropout_rate = 0.3\n\nvit_model = VisionTransformer(image_size, patch_size, num_layers, d_model, num_heads, dff, num_classes, dropout_rate)\n\n# You can compile and train the model using standard Keras methods.\n# For example, using categorical crossentropy loss and the Adam optimizer:\nvit_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory=vit_model.fit(x_train, integer_encoded, epochs=50, batch_size=200, validation_data=(x_test, integer_encoded_test), callbacks=[early_stopping])\n\n# Replace `your_image_data` and `your_labels` with your actual training data\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T20:51:50.308432Z","iopub.status.idle":"2023-12-27T20:51:50.308888Z","shell.execute_reply.started":"2023-12-27T20:51:50.308645Z","shell.execute_reply":"2023-12-27T20:51:50.308667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncallbacks=[]\n\nadam=Adam(learning_rate=0.00001)\nsgd = SGD(learning_rate=0.001, momentum=0.9)","metadata":{"_uuid":"234e24eb-15e3-4f19-906f-3e624447dfe9","_cell_guid":"8ea84b66-a51a-49a8-a95c-ded98aef8797","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.310019Z","iopub.status.idle":"2023-12-27T20:51:50.310474Z","shell.execute_reply.started":"2023-12-27T20:51:50.310243Z","shell.execute_reply":"2023-12-27T20:51:50.310267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom keras.models import Model\n\n# Your existing code for AlexNet\nalex = alex_net()\nalex.layers[0].trainable = False\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=8)\nalex.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\nhistory = alex.fit(x_train, integer_encoded, epochs=50, batch_size=200, validation_data=(x_test, integer_encoded_test), callbacks=[early_stopping])\n","metadata":{"_uuid":"e93149c4-8bfb-43d5-ac1d-76821aa9d752","_cell_guid":"76a3c42c-85f4-4efa-92dd-53c486dcd5c6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.312033Z","iopub.status.idle":"2023-12-27T20:51:50.312549Z","shell.execute_reply.started":"2023-12-27T20:51:50.312284Z","shell.execute_reply":"2023-12-27T20:51:50.312308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the trained model\nmodel_save_path = '/kaggle/working/alexnet_model.h5'\nalex.save(model_save_path)\n\n# Print a message indicating the save path\nprint(f\"Model saved at: {model_save_path}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T20:51:50.313657Z","iopub.status.idle":"2023-12-27T20:51:50.314099Z","shell.execute_reply.started":"2023-12-27T20:51:50.313875Z","shell.execute_reply":"2023-12-27T20:51:50.313897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model('/kaggle/working/alexnet_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T20:51:50.317580Z","iopub.status.idle":"2023-12-27T20:51:50.317944Z","shell.execute_reply.started":"2023-12-27T20:51:50.317756Z","shell.execute_reply":"2023-12-27T20:51:50.317788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wrap the Keras model\nplt.figure(figsize=(10, 5))\n\n# Plot training & validation accuracy values\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"_uuid":"ae85ed74-307a-4806-abc1-0bb8b3cd37ec","_cell_guid":"a0f72b9f-d490-409d-bc24-41b8359e4c2b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.319191Z","iopub.status.idle":"2023-12-27T20:51:50.319497Z","shell.execute_reply.started":"2023-12-27T20:51:50.319346Z","shell.execute_reply":"2023-12-27T20:51:50.319360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'prediction_test' is your test data\npredictions = alex.predict(x_test)\npredicted_labels = np.argmax(predictions, axis=1)","metadata":{"_uuid":"af2c2794-aed6-41ea-9d22-b09e34448b11","_cell_guid":"d765101b-92a2-4f98-8f0d-ed2cd8ab4600","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.320372Z","iopub.status.idle":"2023-12-27T20:51:50.320675Z","shell.execute_reply.started":"2023-12-27T20:51:50.320522Z","shell.execute_reply":"2023-12-27T20:51:50.320537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\ndata = {'image_id': [], 'label': []}\n\n# Assuming 'x_test' is your test data\npredictions = alex.predict(X_test)\npredicted_labels = np.argmax(predictions, axis=1)\n\n# Get the list of file names (without extensions) from the \"test\" directory\ntest_directory = '/kaggle/input/dataset11/dataset/dataset/test'\ntest_file_names = [os.path.splitext(file)[0] for file in os.listdir(test_directory) if is_image_file(file)]\n\n# Update the 'image_id' column with the extracted file names\ndata['image_id'] = test_file_names\nprint(len(test_file_names))\nprint(len(predicted_labels))\n# Update the 'label' column with the predicted labels\ndata['label'] = predicted_labels + 1  # Adding 1 to convert labels back to 1-indexing\n\ndf2 = pd.DataFrame(data)\n\ncsv_file_path = '/kaggle/working/alex.csv'\ndf2.to_csv(csv_file_path, index=False)\n\nprint(f\"CSV file saved at: {csv_file_path}\")\n\nprint(df2.head())\n\n\n","metadata":{"_uuid":"b9b8655b-cb9b-4ce9-bede-8a89389d86d2","_cell_guid":"98f04653-3a80-4078-b296-9939e5096984","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-27T20:51:50.333163Z","iopub.execute_input":"2023-12-27T20:51:50.333835Z","iopub.status.idle":"2023-12-27T20:51:50.374596Z","shell.execute_reply.started":"2023-12-27T20:51:50.333802Z","shell.execute_reply":"2023-12-27T20:51:50.373514Z"},"trusted":true},"execution_count":34,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming 'x_test' is your test data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43malex\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      8\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the list of file names (without extensions) from the \"test\" directory\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'alex' is not defined"],"ename":"NameError","evalue":"name 'alex' is not defined","output_type":"error"}]}]}
